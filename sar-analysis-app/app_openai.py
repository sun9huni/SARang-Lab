import streamlit as st
import pandas as pd
from rdkit import Chem
from utils_v2 import (
    load_data, find_activity_cliffs, generate_hypothesis, draw_highlighted_pair,
    load_pretrained_model, smiles_to_descriptors, find_most_similar_compounds,
    load_feature_list, propose_and_predict_analogs
)
import plotly.express as px
import numpy as np

# --- í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="AI ê¸°ë°˜ SAR/QSAR ë¶„ì„ ì‹œìŠ¤í…œ v2", page_icon="ğŸ’Š", layout="wide")

# --- ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.title("ğŸ”¬ AI-SAR/QSAR ë¶„ì„ ì‹œìŠ¤í…œ")
    st.markdown("---")

    # 1. íƒ€ê²Ÿ ë‹¨ë°±ì§ˆ ì…ë ¥ (RAG ê²€ìƒ‰ì— ì‚¬ìš©)
    target_name = st.text_input(
        "**1. ë¶„ì„ ëŒ€ìƒ íƒ€ê²Ÿ ë‹¨ë°±ì§ˆ**", 
        "EGFR", 
        help="AI ê°€ì„¤ ìƒì„± ì‹œ, ì´ íƒ€ê²Ÿì— ëŒ€í•œ ìµœì‹  ë…¼ë¬¸ì„ ì°¸ì¡°í•˜ì—¬ ì‹ ë¢°ë„ë¥¼ ë†’ì…ë‹ˆë‹¤. ì˜ˆ: EGFR, CDK2, HSP90"
    ).strip().upper()

    st.markdown("---")

    # 2. ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ
    st.markdown("**2. SAR ë¶„ì„ìš© ë°ì´í„°**")
    source_selection = st.radio(
        "ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ", 
        ('ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš©', 'íŒŒì¼ ì—…ë¡œë“œ'), 
        key='source_select', 
        label_visibility="collapsed"
    )
    uploaded_file = None
    if source_selection == 'íŒŒì¼ ì—…ë¡œë“œ':
        uploaded_file = st.file_uploader("SAR ë°ì´í„°(.csv)ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=['csv'])
    else:
        uploaded_file = "sar-analysis-app/data/large_sar_data.csv"
        
    st.markdown("---")
    st.info("íƒ€ê²Ÿì„ ì§€ì •í•˜ë©´, SAR ë¦¬í¬íŠ¸ì˜ AI ê°€ì„¤ì´ í•´ë‹¹ íƒ€ê²Ÿì— ë§ì¶° ìë™ìœ¼ë¡œ ìµœì í™”ë©ë‹ˆë‹¤.")

    # 3. LLM ê³µê¸‰ì ë° API í‚¤ ì…ë ¥
    st.markdown("**3. AI ëª¨ë¸ ì„¤ì •**")
    llm_provider = st.selectbox(
        "AI ëª¨ë¸ ì„ íƒ",
        ("OpenAI", "Gemini")
    )
    
    api_key_placeholder = f"{llm_provider} API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”."
    api_key_help = f"AI ê¸°ë°˜ ë¶„ì„ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ {llm_provider} API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."
    api_key_link = "https://platform.openai.com/api-keys" if llm_provider == "OpenAI" else "https://aistudio.google.com/app/apikey"
    
    api_key = st.text_input(
        "API í‚¤",
        type="password",
        placeholder=api_key_placeholder,
        help=api_key_help,
        label_visibility="collapsed"
    )
    st.caption(f"API í‚¤ëŠ” [{llm_provider} ì›¹ì‚¬ì´íŠ¸]({api_key_link})ì—ì„œ ë°œê¸‰ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

df = load_data(uploaded_file)
# QSARì€ íƒ€ê²Ÿê³¼ ë¬´ê´€í•˜ê²Œ ë‹¨ì¼ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë¯€ë¡œ, í›ˆë ¨ ë°ì´í„° ë¡œë”©ì€ ì œê±°

# --- ë©”ì¸ í˜ì´ì§€ ---
if df is not None:
    tab1, tab2 = st.tabs(["SAR ë¶„ì„ (Activity Cliff)", "QSAR ì˜ˆì¸¡ (AI ë¶„ì ìµœì í™”)"])

    # ==================================
    # SAR ë¶„ì„ íƒ­ (íƒ€ê²Ÿ-íŠ¹í™” RAG ì ìš©)
    # ==================================
    with tab1:
        st.header(f"ğŸ¯ {target_name or 'ë²”ìš©'} íƒ€ê²Ÿ Activity Cliff ë¶„ì„ ë¦¬í¬íŠ¸")
        st.markdown("`Activity Cliff`ë€, êµ¬ì¡°ëŠ” ë§¤ìš° ìœ ì‚¬í•˜ì§€ë§Œ í™œì„±ë„ì—ì„œ í° ì°¨ì´ë¥¼ ë³´ì´ëŠ” í™”í•©ë¬¼ ìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ëŠ” ì‹ ì•½ ê°œë°œì˜ ì¤‘ìš”í•œ ë‹¨ì„œë¥¼ ì œê³µí•©ë‹ˆë‹¤.")
        
        col1, col2 = st.columns([1, 2])
        with col1:
            st.subheader("ë¶„ì„ ì¡°ê±´ ì„¤ì •")
            similarity_threshold = st.slider('ìœ ì‚¬ë„ ì„ê³„ê°’ (Tanimoto)', 0.5, 1.0, 0.8, 0.01, key="sar_sim", on_change=lambda: st.session_state.pop('cliffs', None))
            activity_diff_threshold = st.slider('í™œì„±ë„ ì°¨ì´ ì„ê³„ê°’ (pKi)', 0.5, 3.0, 1.0, 0.1, key="sar_act", on_change=lambda: st.session_state.pop('cliffs', None))

        with col2:
            st.subheader("ë¶„ì„ ëŒ€ìƒ ë°ì´í„°")
            st.dataframe(df, height=200, use_container_width=True)

        st.markdown("---")
        
        if st.button("Activity Cliff ì°¾ê¸°", type="primary", use_container_width=True):
            with st.spinner("Activity Cliffë¥¼ íƒìƒ‰ ì¤‘ì…ë‹ˆë‹¤..."):
                st.session_state['cliffs'] = find_activity_cliffs(df, similarity_threshold, activity_diff_threshold)

        # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
        if 'cliffs' in st.session_state:
            cliffs = st.session_state['cliffs']
            if not cliffs:
                st.warning("ì„¤ì •ëœ ì¡°ê±´ì— ë§ëŠ” Activity Cliffë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.success(f"ì´ {len(cliffs)}ê°œì˜ Activity Cliffë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤. ë¶„ì„í•  ìŒì„ ì„ íƒí•˜ì„¸ìš”.")
                cliff_options = [f"{i+1}. {c['mol_1']['ID']} vs {c['mol_2']['ID']} (Î”pKi: {c['activity_diff']:.2f})" for i, c in enumerate(cliffs)]
                selected_option = st.selectbox("ë¶„ì„í•  Activity Cliff ì„ íƒ:", cliff_options, key='cliff_select')
                selected_index = cliff_options.index(selected_option)
                selected_cliff = cliffs[selected_index]
                
                st.subheader("2. í•µì‹¬ ë¶„ì„ ë¦¬í¬íŠ¸")
                
                # í•˜ì´ë¼ì´íŒ…ëœ ë¶„ì êµ¬ì¡° í‘œì‹œ
                mol1_svg, mol2_svg = draw_highlighted_pair(selected_cliff['mol_1']['SMILES'], selected_cliff['mol_2']['SMILES'])
                
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown(f"**í™”í•©ë¬¼ 1: {selected_cliff['mol_1']['ID']}**")
                    st.image(mol1_svg)
                    st.metric("pKi", f"{selected_cliff['mol_1']['pKi']:.2f}")

                with col2:
                    st.markdown(f"**í™”í•©ë¬¼ 2: {selected_cliff['mol_2']['ID']}**")
                    st.image(mol2_svg)
                    st.metric("pKi", f"{selected_cliff['mol_2']['pKi']:.2f}")

                st.info(f"**Tanimoto ìœ ì‚¬ë„:** {selected_cliff['similarity']:.3f} | **í™œì„±ë„(pKi) ì°¨ì´:** {selected_cliff['activity_diff']:.3f}")

                # AI ê°€ì„¤ ìƒì„±
                with st.spinner("AIê°€ ì°¸ê³  ë¬¸í—Œì„ ê²€ìƒ‰í•˜ê³  ê°€ì„¤ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    if not api_key:
                        st.warning("ì‚¬ì´ë“œë°”ì— API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    else:
                        hypothesis, source_info = generate_hypothesis(selected_cliff, target_name, api_key, llm_provider)
                        st.subheader("3. ìë™í™”ëœ í•´ì„ ë° ê°€ì„¤ (AI-Generated Hypothesis)")
                        st.markdown(hypothesis)

                        if source_info:
                            with st.expander("ğŸ“š ì°¸ê³  ë¬¸í—Œ ì •ë³´ (RAG ê·¼ê±°)"):
                                st.markdown(f"**- ì œëª©:** {source_info['title']}")
                                st.markdown(f"**- ë§í¬:** [PubMed ë°”ë¡œê°€ê¸°]({source_info['link']})")
                                st.text_area("ì´ˆë¡(Abstract)", source_info['abstract'], height=200)


    # ==================================
    # QSAR ì˜ˆì¸¡ íƒ­ (ë‹¨ì¼ ëª¨ë¸ ì‚¬ìš©)
    # ==================================
    with tab2:
        st.header("ğŸ’¡ AI ê¸°ë°˜ ë¶„ì ìµœì í™” ì œì•ˆ")
        st.markdown("ê¸°ì¤€ í™”í•©ë¬¼ì˜ SMILESë¥¼ ì…ë ¥í•˜ë©´, AIê°€ í™œì„±ë„ ê°œì„ ì´ ì˜ˆìƒë˜ëŠ” ìƒˆë¡œìš´ ë¶„ì êµ¬ì¡°ë¥¼ ì œì•ˆí•˜ê³ , ì‚¬ì „ í›ˆë ¨ëœ QSAR ëª¨ë¸ë¡œ í™œì„±ë„ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")
        
        model_pipeline, msg = load_pretrained_model()
        features, f_msg = load_feature_list()

        if model_pipeline and features:
            base_smiles = st.text_input("ê¸°ì¤€ í™”í•©ë¬¼ SMILES ì…ë ¥", "c1ccc(cc1)c2[nH]c3ccc(C)cc3n2")

            if st.button("AI ìµœì í™” ì œì•ˆ ë°›ê¸°", type="primary", use_container_width=True):
                if not api_key:
                    st.error(f"ì‚¬ì´ë“œë°”ì— {llm_provider} API í‚¤ë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    base_mol = Chem.MolFromSmiles(base_smiles)
                    if base_mol:
                        with st.spinner(f"{llm_provider} AIê°€ ìƒˆë¡œìš´ ë¶„ìë¥¼ ì„¤ê³„í•˜ê³  QSAR ëª¨ë¸ë¡œ í™œì„±ì„ ì˜ˆì¸¡ ì¤‘ì…ë‹ˆë‹¤..."):
                            proposals = propose_and_predict_analogs(base_smiles, model_pipeline, features, api_key, llm_provider)
                        
                        if proposals:
                            st.subheader("âœ¨ AI ì œì•ˆ ë° ì˜ˆì¸¡ ê²°ê³¼")
                            
                            st.markdown("---")
                            st.markdown(f"**ê¸°ì¤€ í™”í•©ë¬¼:** `{base_smiles}`")
                            base_features = smiles_to_descriptors(base_smiles, features)
                            if base_features is not None:
                                feature_df = pd.DataFrame([base_features], columns=features)
                                predicted_base_pki = model_pipeline.predict(feature_df)[0]
                                st.metric("ê¸°ì¤€ í™”í•©ë¬¼ ì˜ˆì¸¡ pKi", f"{predicted_base_pki:.2f}")
                            st.image(draw_molecule(base_smiles))
                            st.markdown("---")

                            for i, prop in enumerate(proposals):
                                st.markdown(f"##### ì œì•ˆ {i+1}")
                                st.image(draw_molecule(prop['smiles']))
                                st.metric(f"ì œì•ˆ {i+1} ì˜ˆì¸¡ pKi", f"{prop['predicted_pki']:.2f}", delta=f"{prop['predicted_pki'] - predicted_base_pki:.2f}")
                                st.info(f"**AI ì œì•ˆ ì´ìœ :** {prop['reason']}")
                                st.code(prop['smiles'], language='text')
                                st.markdown("---")

                        else:
                            st.error("AIê°€ ìœ íš¨í•œ ë¶„ìë¥¼ ì œì•ˆí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                    else:
                        st.error("ì…ë ¥í•œ SMILES ë¬¸ìì—´ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        else:
            st.error(f"ëª¨ë¸ ë˜ëŠ” í”¼ì²˜ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {msg or f_msg}")

else:
    st.warning("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
